{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJBs_flRovLc"
      },
      "source": [
        "## Using spaCy for NLP Tasks\n",
        "\n",
        "This notebook demonstrates how to install and use spaCy to perform various Natural Language Processing (NLP) tasks.\n",
        "\n",
        "In today’s lesson we will:\n",
        "\n",
        "- Install spaCy and download its statistical models.\n",
        "- Read and process a text file.\n",
        "- Perform Named Entity Recognition (NER) to extract entities from text.\n",
        "- Visualize entity counts.\n",
        "- Explore and customize the spaCy pipeline (including using the EntityRuler)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ans8WJUUj8qI"
      },
      "source": [
        "### 1. Installation\n",
        "To get started, you must install spaCy and the English language model.\n",
        "\n",
        "**Instructions:**\n",
        "\n",
        "1. Use `pip install spacy` to install the core library.\n",
        "2. Download the English model (`en_core_web_sm`) which includes the statistical model for English.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "s8aj7OGAkCcx"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spacy in /opt/anaconda3/lib/python3.12/site-packages (3.8.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (8.3.4)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (0.9.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (4.66.5)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (1.26.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (2.8.2)\n",
            "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /opt/anaconda3/lib/python3.12/site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.12.14)\n",
            "Requirement already satisfied: blis<1.3.0,>=1.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.2.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /opt/anaconda3/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /opt/anaconda3/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (5.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->spacy) (2.1.3)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ],
      "source": [
        "!pip install spacy\n",
        "!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCjfqkKMkrY-"
      },
      "source": [
        "### 2. Loading the spaCy Model\n",
        "\n",
        "Once downloaded, those models can be opened via **spacy.load('model_name')** in python. Therefore, you can verify if the models were downloaded successfully by running the following code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "gJr_9dXGpJ05"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFPkM3QLc9qf"
      },
      "source": [
        "### 3. Reading a Text File\n",
        "Here, we read in a text file that contains a chapter from *The Fellowship Of The Ring*. Make sure the file is in your working directory (or provide the full path).\n",
        "\n",
        "**Key Steps:**\n",
        "- Open the file using Python’s built-in `open()` function.\n",
        "- Read the content into a variable.\n",
        "- Adjust `nlp.max_length` to avoid errors when processing long texts.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "f9MWj4EuNvNK"
      },
      "outputs": [],
      "source": [
        "# Define the file path (adjust this path if your file is stored elsewhere)\n",
        "lotr_script = 'The Fellowship Of The Ring_Ch1.txt'\n",
        "\n",
        "# Read the file content\n",
        "with open(lotr_script, 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "\n",
        "# Adjust the maximum allowed length for the NLP model to process the full text\n",
        "nlp.max_length = len(text)\n",
        "\n",
        "# Process the text with the spaCy model\n",
        "doc = nlp(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "-gE-Ez1qtyIA"
      },
      "outputs": [],
      "source": [
        "# Increase the max_length to handle the large text, avoids an error\n",
        "nlp.max_length = len(text) # Sets the maximum length to the length of the text\n",
        "\n",
        "doc = nlp(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exe29dKGjGir"
      },
      "source": [
        "### 4. Named Entity Recognition (NER)\n",
        "\n",
        "Named Entity Recognition identifies and classifies entities (like names of people, places, or organizations) in text.\n",
        "**What we'll do:**\n",
        "- Extract entities from the processed document.\n",
        "- Create a Pandas DataFrame that shows the entity text and its corresponding label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "_5etHS43jL0g"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Chapter 1</td>\n",
              "      <td>LAW</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Party</td>\n",
              "      <td>ORG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Bilbo Baggins</td>\n",
              "      <td>PERSON</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Bag End</td>\n",
              "      <td>ORG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>first</td>\n",
              "      <td>ORDINAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>520</th>\n",
              "      <td>Shire</td>\n",
              "      <td>PERSON</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>521</th>\n",
              "      <td>Gandalf</td>\n",
              "      <td>NORP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>522</th>\n",
              "      <td>Frodo</td>\n",
              "      <td>ORG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>523</th>\n",
              "      <td>Frodo</td>\n",
              "      <td>ORG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>524</th>\n",
              "      <td>evening</td>\n",
              "      <td>TIME</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>525 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              text    label\n",
              "0        Chapter 1      LAW\n",
              "1            Party      ORG\n",
              "2    Bilbo Baggins   PERSON\n",
              "3          Bag End      ORG\n",
              "4            first  ORDINAL\n",
              "..             ...      ...\n",
              "520          Shire   PERSON\n",
              "521        Gandalf     NORP\n",
              "522          Frodo      ORG\n",
              "523          Frodo      ORG\n",
              "524        evening     TIME\n",
              "\n",
              "[525 rows x 2 columns]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create a list to collect entity data\n",
        "entities_data = []\n",
        "\n",
        "# Extract each entity and its label from the document\n",
        "for ent in doc.ents:\n",
        "    entities_data.append({\n",
        "        \"text\": ent.text,\n",
        "        \"label\": ent.label_\n",
        "    })\n",
        "\n",
        "# Convert the list into a DataFrame for easier viewing\n",
        "ent_df = pd.DataFrame(entities_data)\n",
        "# Display the entities\n",
        "ent_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oH8kcexJU5g8"
      },
      "source": [
        "### 5. Analyzing Entity Data\n",
        "Let's examine:\n",
        "- **Text and Label Frequency:**  \n",
        "Display the most common entity texts and their labels.\n",
        "- **Entity Details:**  \n",
        "Use spaCy's built-in explanation function to understand what a specific label (e.g., \"FAC\") means."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "K0R0AmwYV_qj"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Countries, cities, states'"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Display the top 15 most common texts and labels\n",
        "ent_df[\"text\"].value_counts()[:15]\n",
        "ent_df[\"label\"].value_counts()[:15]\n",
        "\n",
        "# Explain a specific entity label\n",
        "spacy.explain(\"GPE\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "drU2gC30_g8q"
      },
      "outputs": [],
      "source": [
        "# Display combinations of text and label counts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ws6P7bHT_i0b"
      },
      "outputs": [],
      "source": [
        "# List unique labels in the dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHksIATSjXEF"
      },
      "source": [
        "###  6. Exploring the NLP Pipeline\n",
        "[NLP Pipeline Documentation](https://spacy.io/usage/processing-pipelines#processing)\n",
        "\n",
        "You can inspect the components of the NLP pipeline `nlp.pipeline`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q9iiD5GBdTNu"
      },
      "outputs": [],
      "source": [
        "# Spacy's language model pipeline\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gw9yYQJlWbpu"
      },
      "source": [
        "### 7. Visualizing Entities with DisplaCy\n",
        "DisplaCy is spaCy’s visualization tool for rendering entities and dependencies in Jupyter notebooks.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DafBeVakWgQl"
      },
      "outputs": [],
      "source": [
        "from spacy import displacy\n",
        "\n",
        "# Render entities in the processed document using DisplaCy\n",
        "displacy.render(doc, style = \"ent\", jupyter = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiKdRq51h6BD"
      },
      "source": [
        "### 8. Identifying Issues in the Named Entity Recognizer\n",
        "\n",
        "Use the [Lord of the Rings Wiki](https://lotr.fandom.com/wiki/Main_Page) if you need help\n",
        "\n",
        "Example Issues: ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEXt_fWGgvw-"
      },
      "source": [
        "### 9. Creating Custom Entity Recognizers with the EntityRuler\n",
        "\n",
        "Custom patterns can be added to the pipeline using spaCy's `EntityRuler`. This allows us to capture entities that might be missed by the statistical model.\n",
        "\n",
        "**Steps:**\n",
        "- Define custom entity patterns (as a list of dictionaries).\n",
        "- Check if the \"ner\" component exists and add the EntityRuler accordingly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLIskVAMQ29B"
      },
      "source": [
        "[EntityRuler Documentation](https://spacy.io/api/entityruler#add_patterns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "giLScuq6KIel"
      },
      "outputs": [],
      "source": [
        "# Define custom entity patterns for names, locations, and other entities\n",
        "entity_patterns = [\n",
        "\n",
        "\n",
        " ]\n",
        "\n",
        "#Add EntityRuler to the pipeline\n",
        "#ruler = nlp.add_pipe(\"entity_ruler\", before=\"ner\")\n",
        "#ruler.add_patterns(entity_patterns)\n",
        "\n",
        "#Access the existing entity_ruler\n",
        "#ruler = nlp.get_pipe(\"entity_ruler\")\n",
        "\n",
        "#Add your custom patterns\n",
        "#ruler.add_patterns(entity_patterns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xZMQGkZXFv2q"
      },
      "outputs": [],
      "source": [
        "# Check if the \"ner\" pipe exists. If it does, add the EntityRuler before it.\n",
        "\n",
        "    # If entity_ruler already exists, simply add patterns to it.\n",
        "\n",
        "    # If the NER component does not exist, add both the EntityRuler and the NER component.\n",
        "\n",
        "# Check updated pipeline labels\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Opw-lzPZWsU"
      },
      "source": [
        "### 10. Testing the Custom Entity Ruler\n",
        "Run a sample sentence through the updated pipeline to check if your custom patterns are recognized.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2O5Ge2r3LP9u"
      },
      "outputs": [],
      "source": [
        "from spacy import displacy\n",
        "\n",
        "doc_2 = nlp(\"Gandalf went to Bilbo's house for his birthday because he was my precious which is the Ring.\")\n",
        "displacy.render(doc_2, style=\"ent\", jupyter=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPOU5FyuQ-Md"
      },
      "source": [
        "### 11. Re-Processing the Full Text\n",
        "Now that we have updated the pipeline with our custom patterns, re-run the full text to see how the recognizer performs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62RVMVg6M3DW"
      },
      "outputs": [],
      "source": [
        "# Re-process the text with the updated pipeline\n",
        "nlp.max_length = len(text)\n",
        "doc = nlp(text)\n",
        "\n",
        "displacy.render(doc, style=\"ent\", jupyter=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qeVGXJYmYySk"
      },
      "source": [
        "### 12. Re-Analyzing Entity Data\n",
        "Let's again create a DataFrame from the updated document to see if our custom recognitions improved entity extraction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jh-a6rd-mDpO"
      },
      "outputs": [],
      "source": [
        "# Collect entities from the updated document\n",
        "entities_data = []\n",
        "for ent in doc.ents:\n",
        "    entities_data.append({\n",
        "        'text': ent.text,\n",
        "        'label': ent.label_\n",
        "    })\n",
        "\n",
        "# Convert to DataFrame and display\n",
        "ent_df = pd.DataFrame(entities_data)\n",
        "ent_df\n",
        "\n",
        "# %%\n",
        "# Show value counts for text and label combinations after the update\n",
        "print(\"Updated Text and Label Combinations (Top 20):\")\n",
        "print(ent_df[['text', 'label']].value_counts()[:20])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVbasK5wXAX_"
      },
      "source": [
        "### 13. Visualizing Entity Data\n",
        "Finally, we create a bar plot to visualize the top 10 most common text and label combinations.\n",
        "**Steps:**\n",
        "- Use Pandas to compute counts.\n",
        "- Plot the counts using Seaborn and Matplotlib.\n",
        "\n",
        "**Tree Map**\n",
        "- The `color` parameter is set to `label` so that each entity label gets a distinct color.\n",
        "\n",
        "- The `path` parameter defines a hierarchy where entities are grouped by their `label` first, then by `text`.\n",
        "\n",
        "- This interactive treemap allows students to easily see how different entity labels contribute to the overall counts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8IZa1cJHlamc"
      },
      "outputs": [],
      "source": [
        "import plotly.express as px\n",
        "\n",
        "# Prepare the data for visualization: top 10 entity combinations\n",
        "top_10_ents = ent_df[['text', 'label']].value_counts().head(10).reset_index(name='counts')\n",
        "\n",
        "# Create a treemap using a hierarchical structure (first by label, then by text)\n",
        "fig = px.treemap(top_10_ents,\n",
        "                path=['label', 'text'],\n",
        "                values='counts',\n",
        "                title='Top 10 Text and Label Combinations (Treemap)',\n",
        "                color='label')\n",
        "\n",
        "fig.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
